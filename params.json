{"name":"Analytics Challenge","tagline":"","body":"### Initial Process - Determining How to Analyze the Data\r\n\r\nUpon receiving the content for the data analytics challenge, there were several different methods for sorting the data that were tried -- sorting the data chronologically didn’t work very well, because there was so much variance in the volume of content gathered each month. It seemed that the best way to sort the data was the most straightforward - by bank.  We gave 5 categories to the data: content mentioning Bank A, Bank B, Bank C, Bank D, and all other content (other banks or no banks mentioned).  We also paid some attention to the split between content generated on facebook and content generated on twitter.\r\n\r\n\r\nFor a deeper analysis, a semi­-random sample of 80 content posts was taken and given extra classifications according to topic, cause of post, and audience. This sample was obtained by taking a random sample of 100 content posts from the first four categories, keeping with the comparative method used so far, and then determining which posts out of the 100 were meaningful. The information gleaned from this analysis, combined with our coded analysis, provided us with a cohesive narrative regarding why people post, what they post about, and who their audience is, and how each bank is regarded comparatively.\r\n\r\n\r\n### Sentiment Analysis\r\n\r\nIn the coding process, a random sample (~10,000 posts) of the consumer content was divided into 5 categories: content mentioning BankA(1), BankB(2), BankC(3), BankD(4), or none of the four banks(5). By using a sentiment analysis patch in the code, content was categorized as positive or negative, and each of the 5 categories was then scored according to their amount of positive vs. negative content. This gives a rough idea of how consumers perceive each bank on a large scale.\r\n\r\nWe used a sentiment analysis patch in our code; an excerpt is detailed below:\r\n\r\n    score.sentiment = function(sentences, pos.words, neg.words, .progress='none')\r\n    {\r\n    require(plyr)\r\n    require(stringr)\r\n  \r\n    # we got a vector of sentences. plyr will handle a list\r\n    # or a vector as an \"l\" for us\r\n    # we want a simple array (\"a\") of scores back, so we use \r\n    # \"l\" + \"a\" + \"ply\" = \"laply\":\r\n    scores = laply(sentences, function(sentence, pos.words, neg.words) {\r\n    \r\n    # clean up sentences with R's regex-driven global substitute, gsub():\r\n    sentence = gsub('[[:punct:]]', '', sentence)\r\n    sentence = gsub('[[:cntrl:]]', '', sentence)\r\n    sentence = gsub('\\\\d+', '', sentence)\r\n    # and convert to lower case:\r\n    sentence = tolower(sentence)\r\n    \r\n    # split into words. str_split is in the stringr package\r\n    word.list = str_split(sentence, '\\\\s+')\r\n    # sometimes a list() is one level of hierarchy too much\r\n    words = unlist(word.list)\r\n    \r\n    # compare our words to the dictionaries of positive & negative terms\r\n    pos.matches = match(words, pos.words)\r\n    neg.matches = match(words, neg.words)\r\n    \r\n    # match() returns the position of the matched term or NA\r\n    # we just want a TRUE/FALSE:\r\n    pos.matches = !is.na(pos.matches)\r\n    neg.matches = !is.na(neg.matches)\r\n    \r\n    # and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():\r\n    score = sum(pos.matches) - sum(neg.matches)\r\n    \r\n    return(score)\r\n    }, pos.words, neg.words, .progress=.progress )\r\n  \r\n    scores.df = data.frame(score=scores, text=sentences)\r\n    return(scores.df)\r\n    }\r\n\r\n### The Data\r\n\r\nFor the following graphs, the data is organized into groups: 0 is Bank A, 1 is Bank B, 2 is Bank C, 3 is Bank D, 4 is no banks/other banks\r\n\r\n![Average Sentiment Score](http://i.imgur.com/f1pNfVO.png)\r\n\r\nThe average overall scores among the banks - Bank A has the highest overall score\r\n\r\n![Average Positive Scores](http://i.imgur.com/i8Mvtzo.png)\r\n\r\nThe average positive scores among the banks - Bank B has the highest positive score\r\n\r\n![Average Negative Scores](http://i.imgur.com/Lzm6kEm.png)\r\n\r\nThe average negative scores among the banks - Bank C has the highest negative score\r\n\r\n\r\n### In Depth Analysis\r\n\r\nIn depth analysis was used to get a list of topics and substances for the user-generated content, as well as to determine the intended audience of the content.  This was done by taking 20 posts/tweets from each bank and determining the subject or topic of the post, what caused the user to post (substance), and the intended audience. \r\n\r\nAbout ⅓ of the content was directed at the bank itself, and close to ⅔ of the content was directed at a general audience; a very small percent of the content was directed at a customer from the bank.\r\n\r\nOverall, almost all of the content posts regarding customer service that were analyzed were caused by a bad experience. Other topics, such as PR, had greater contrast within their substance -- the majority of posts here were shared news articles, but also included some appreciation posts, mostly for Bank A and Bank B.  This agrees with our sentiment analysis that Bank A and Bank B are the banks with the highest sentiment score, and the greatest number of positive posts.  However, Bank A and Bank B also garnered their fair share of negative feedback; much of the feedback across all banks was negative, especially concerning customer service. \r\n\r\nOne of the most notable aspects of the topic distribution was the fact that Bank D was the only bank with a significant number of posts about security; when sorted by date, the bulk of these posts occur in September/October of 2014, likely tying them to a specific breach of security rather than an ongoing problem with the bank’s infrastructure.\r\n\r\n### Suggestions for Further Research\r\n\r\nIn determining what would give our data greater meaning, the largest issue is how well the sentiment analysis works.  Some tweets, such as this one:\r\n\r\n        “i would like to send out a special thank you to the teller at the BankA \r\n         for telling everyone at the top of her lungs how much cash i just deposited \r\n         into my account and the last four numbers of my account! great job and thanks \r\n         for the discretion!”\r\n\r\nwould likely have been scored positively.  The deeper meaning (ingratitude vs. gratitude) is not evident without knowing that the situation described is the opposite of discretion, and we aren’t able to check for sarcasm with an algorithm.  In the future, it would be a good idea to take a sample of the code-scored content and cross-check it against a human score, thus determining how much the sentiment analysis can be trusted overall.\r\n\r\nAdditionally, while we sorted the content for usefulness for some of our analysis ( the 20 posts from each bank used for in depth analysis were pared down from a sample of 100 each, and judged on whether or not they carried a lot of meaning), it would be helpful in the future to do this for more of the content.  This is a timely process, but would greatly increase how useful the results are, as results are only as useful as the data they are derived from.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}